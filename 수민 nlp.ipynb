{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 1871, in run\n",
      "    for msg in self.data_server.incr_download(self.items):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 535, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 578, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 549, in incr_download\n",
      "    for msg in self.incr_download(info.children, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 535, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 578, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 555, in incr_download\n",
      "    for msg in self._download_package(info, download_dir, force):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 606, in _download_package\n",
      "    os.remove(filepath)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\chlje\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\treebank.zip'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Sumin Seo\n",
    "# Computer Linguistic Basic\n",
    "\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-00ca13d1cbf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# ~으로 끝나는 text1의 모든 단어를 정렬하라\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ableness'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# function set()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text1' is not defined"
     ]
    }
   ],
   "source": [
    "## python basics\n",
    "# <, ==, !=\n",
    "# functions: startswith(), endswith(), t in s, islower(), isupper(), isalpha()\n",
    "# isalnum(), isdigit(), istitle()\n",
    "\n",
    "# ~으로 끝나는 text1의 모든 단어를 정렬하라\n",
    "sorted(w for w in set(text1) if w.endswith('ableness'))\n",
    "\n",
    "# function set()\n",
    "# 문장의 길이와 set 길이 차이를 알아보자\n",
    "print(len(text1))\n",
    "print(len(set(word.lower() for word in text1)))\n",
    "\n",
    "## file load\n",
    "f = open(\"example.txt\")\n",
    "for line in f.readlines():\n",
    "    print(line)\n",
    "f.close()\n",
    "\n",
    "## collocation with words\n",
    "text1.concordance('monstrous')\n",
    "text2.common_contexts([\"monstrous\", \"very\"])\n",
    "\n",
    "### Text Normalization\n",
    "#1 Segmenting(tokenizing)\n",
    "#2 Normalizing - case folding, lemmatization, stemming\n",
    "\n",
    "## tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "f = open(\"example.txt\")\n",
    "tokens = []\n",
    "\n",
    "for line in f.readlines():\n",
    "    token = word_tokenize(line)\n",
    "    for i in token:\n",
    "        tokens.append(i)\n",
    "print(tokens)\n",
    "f.close()\n",
    "\n",
    "## POS tagging\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)\n",
    "\n",
    "## stemming\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "text1 = \"He is running faster than her.\"\n",
    "text2 = \"My cats are swimming in the pool with the birds\"\n",
    "text3 = \"He is taller than me\"\n",
    "\n",
    "ps.stem(\"loving\")\n",
    "ps.stem(\"cars\")\n",
    "ps.stem(\"children\")  # not work\n",
    "ps.stem(\"feet\")  # not work\n",
    "\n",
    "# 토큰화 먼저 해야함, 잘못된 예시\n",
    "for w in text1:\n",
    "    print(ps.stem(w))\n",
    "\n",
    "## lemmatization\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "# 동사랑 형용사는 잘 안됨\n",
    "lem.lemmatize(\"running\")\n",
    "lem.lemmatize(\"supported\")\n",
    "lem.lemmatize(\"best\")\n",
    "\n",
    "# lemmatize 함수는 2 arguments를 취하는 함수, 토큰과 품사(default = 'n')\n",
    "lem.lemmatize(\"running\", pos='v')\n",
    "lem.lemmatize(\"supported\", pos='v')\n",
    "lem.lemmatize(\"been\", pos='v')\n",
    "lem.lemmatize(\"happier\", pos='a')\n",
    "lem.lemmatize(\"worst\", pos='a')\n",
    "lem.lemmatize(\"worse\", pos='a')\n",
    "\n",
    "sent = \"The children were given a book.\"\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "tag = nltk.pos_tag(tokens)\n",
    "\n",
    "# sent의 token을 모두 원형(lemma) 형태로 반환해보자\n",
    "# 1번째 방법\n",
    "lemList = []\n",
    "for i in tag :\n",
    "    if (i[1] in ('VBP','VBG','VBN','VBD','VBZ')):\n",
    "        lemWord = lem.lemmatize(i[0], pos='v')\n",
    "    else:\n",
    "        lemWord = lem.lemmatize(i[0])\n",
    "    lemList.append(lemWord)\n",
    "\n",
    "# 2번째 방법\n",
    "lemList2 = []\n",
    "for (a, b) in tag:\n",
    "    if a != '.':\n",
    "        if b.startswith('JJ'):\n",
    "            lemList2 += [lem.lemmatize(a, pos='a')]\n",
    "        elif b.startswith('V'):\n",
    "            lemList2 += [lem.lemmatize(a, pos='v')]\n",
    "        elif b.startswith('R'):\n",
    "            lemList2 += [lem.lemmatize(a, pos='r')]\n",
    "        else:\n",
    "            lemList2 += [lem.lemmatize(a)]\n",
    "    else:\n",
    "        lemList2 += [a]\n",
    "\n",
    "print(lemList)\n",
    "print(lemList2)\n",
    "\n",
    "# 주의사항\n",
    "# for word in tag -> (token, pos) 형식으로 되어 있어야함\n",
    "# word [1] -> 'nns' -> n 으로 바꾸기\n",
    "# tuple unchangable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
